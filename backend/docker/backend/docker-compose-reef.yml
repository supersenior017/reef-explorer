version: '3.7'

services:
  #
  # reef node
  #
  substrate-node:
    image: reef-node/latest
    hostname: substrate-node
    build: ./reef-node
    volumes:
      - 'substrate-data:/data'
    ports:
      - '30333:30333'
      - '9933:9933'
      - '9944:9944'
    expose:
      - '9944'
    command: -d /data --chain testnet --pruning=archive --rpc-cors "*" --ws-port 9944 --port 30333 --unsafe-ws-external --no-prometheus --name 'Reef explorer' --telemetry-url 'wss://telemetry.polkadot.io/submit/ 0'
    restart: always

  #
  # SQL data base
  #
  postgres:
    image: postgres
    restart: always
    volumes:
      - 'db-data:/var/lib/postgresql/data'
      - './sql/backend.sql:/docker-entrypoint-initdb.d/backend.sql'
    environment:
      POSTGRES_USER: 'reef'
      POSTGRES_PASSWORD: 'reef'
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U reef']
      interval: 5s
      timeout: 5s
      retries: 5
  #
  # Hasura GraphQL server
  #
  graphql-engine:
    image: hasura/graphql-engine:v1.3.3
    ports:
      - '8082:8080'
    depends_on:
      - 'postgres'
    restart: always
    environment:
      HASURA_GRAPHQL_DATABASE_URL: postgres://reef:reef@postgres:5432/reef
      HASURA_GRAPHQL_ENABLE_CONSOLE: 'false' # set to "false" to disable console
      HASURA_GRAPHQL_ENABLED_LOG_TYPES: startup, http-log, webhook-log, websocket-log, query-log
      ## uncomment next line to set an admin secret
      # HASURA_GRAPHQL_ADMIN_SECRET: myadminsecretkey
  #
  # Chain crawler
  #
  crawler:
    image: crawler:latest
    build:
      context: ../../
      dockerfile: ./docker/backend/crawler/Dockerfile
    depends_on:
      - 'postgres'
      - 'substrate-node'
    restart: on-failure
    environment:
      - NODE_ENV=production
      - WS_PROVIDER_URL=ws://substrate-node:9944
      - SUBSTRATE_NETWORK=reef
      # - CRAWLER_BLOCK_LISTENER_DISABLE=true
      # - CRAWLER_BLOCK_HARVESTER_DISABLE=true
#
# Persisten volumes
#
volumes:
  db-data: {}
  substrate-data: {}
